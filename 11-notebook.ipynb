{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungsblatt 11\n",
    "## Präsenzaufgaben\n",
    "### Aufgabe 1 &nbsp;&nbsp;&nbsp; Grammatikinduktion\n",
    "In dieser Aufgabe soll vollautomatisch aus Daten (Syntaxbäumen) eine probabilistische, kontextfreie Grammatik erzeugt werden.\n",
    "\n",
    "Füllen Sie die Lücken und versuchen Sie mithilfe Ihrer automatisch erstellten Grammatik die folgenden Sätze zu parsen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"the men saw a car .\",\n",
    "    \"the woman gave the man a book .\",\n",
    "    \"she gave a book to the man .\",\n",
    "    \"yesterday , all my trouble seemed so far away .\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.grammar import ProbabilisticProduction, PCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production count: the number of times a given production occurs\n",
    "pcount = {}\n",
    "\n",
    "# LHS-count: counts the number of times a given lhs occurs\n",
    "lcount = {}\n",
    "\n",
    "for tree in []:\n",
    "    pass\n",
    "        \n",
    "productions = [\n",
    "    ProbabilisticProduction(\n",
    "        p.lhs(), p.rhs(),\n",
    "        prob=None\n",
    "    )\n",
    "    for p in pcount\n",
    "]\n",
    "\n",
    "start = nltk.Nonterminal('S')\n",
    "# grammar = PCFG(start, productions)\n",
    "# parser = nltk.ViterbiParser(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2 &nbsp;&nbsp;&nbsp; Informationsextraktion per Syntaxanalyse\n",
    "Gegenstand dieser Aufgabe ist eine anwendungsnahe Möglichkeit, Ergebnisse einer Syntaxanalyse weiterzuverarbeiten. Aus den syntaktischen Abhängigkeiten eines Textes soll (unter Zuhilfenahme einiger Normalisierungsschritte) eine semantische Repräsentation der im Text enthaltenen Informationen gewonnen werden.\n",
    "\n",
    "Für die syntaktische Analyse soll der `DependencyParser` der Stanford CoreNLP Suite verwendet werden. Die semantische Repräsentation eines Satzes sei ein zweistelliges, logisches Prädikat, dessen Argumente durch Subjekt und Objekt gefüllt sind. (Bei Fehlen eines der beiden Elemente soll `None` geschrieben werden.)\n",
    "\n",
    "Folgendes Beispiel illustriert das gewünschte Ergebnis:\n",
    "\n",
    "Eingabe:\n",
    "\n",
    "    I shot an elephant in my pajamas.\n",
    "    The elephant was seen by a giraffe in the desert.\n",
    "    The bird I need is a raven.\n",
    "    The man who saw the raven laughed out loud.\n",
    "\n",
    "Ausgabe:\n",
    "\n",
    "    shot(I, elephant)\n",
    "    seen(giraffe, elephant)\n",
    "    need(I, bird)\n",
    "    raven(bird, None)\n",
    "    saw(man, raven)\n",
    "    laughed(man, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass `PATH_TO_CORE` in folgender Code-Zelle Ihrem System entsprechend angepasst werden muss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "\n",
    "PATH_TO_CORE = \"/pfad/zu/stanford-corenlp-full-2017-06-09/\"\n",
    "jar = PATH_TO_CORE + \"stanford-corenlp-3.8.0.jar\"\n",
    "model = PATH_TO_CORE + \"stanford-corenlp-3.8.0-models.jar\"\n",
    "\n",
    "dep_parser = StanfordDependencyParser(\n",
    "    jar, model,\n",
    "    model_path=\"edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_predicates_for_sentence(sentence):\n",
    "    for result in dep_parser.raw_parse(sentence):\n",
    "        for triple in result.triples():\n",
    "            print(*triple)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shot', 'VBD') nsubj ('I', 'PRP')\n",
      "('shot', 'VBD') dobj ('elephant', 'NN')\n",
      "('elephant', 'NN') det ('an', 'DT')\n",
      "('shot', 'VBD') nmod ('pajamas', 'NNS')\n",
      "('pajamas', 'NNS') case ('in', 'IN')\n",
      "('pajamas', 'NNS') nmod:poss ('my', 'PRP$')\n"
     ]
    }
   ],
   "source": [
    "for pred in generate_predicates_for_sentence(\n",
    "    \"I shot an elephant in my pajamas.\"\n",
    "):\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_predicates_for_text(text):\n",
    "    predicates = []\n",
    "    for sent in nltk.tokenize.sent_tokenize(text):\n",
    "        predicates.extend(generate_predicates_for_sentence(sent))\n",
    "    return predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('shot', 'VBD') nsubj ('I', 'PRP')\n",
      "('shot', 'VBD') dobj ('elephant', 'NN')\n",
      "('elephant', 'NN') det ('an', 'DT')\n",
      "('shot', 'VBD') nmod ('pajamas', 'NNS')\n",
      "('pajamas', 'NNS') case ('in', 'IN')\n",
      "('pajamas', 'NNS') nmod:poss ('my', 'PRP$')\n",
      "('seen', 'VBN') nsubjpass ('elephant', 'NN')\n",
      "('elephant', 'NN') det ('The', 'DT')\n",
      "('seen', 'VBN') auxpass ('was', 'VBD')\n",
      "('seen', 'VBN') nmod ('giraffe', 'NN')\n",
      "('giraffe', 'NN') case ('by', 'IN')\n",
      "('giraffe', 'NN') det ('a', 'DT')\n",
      "('raven', 'NN') nsubj ('bird', 'NN')\n",
      "('bird', 'NN') det ('The', 'DT')\n",
      "('bird', 'NN') acl:relcl ('need', 'VBP')\n",
      "('need', 'VBP') nsubj ('I', 'PRP')\n",
      "('raven', 'NN') cop ('is', 'VBZ')\n",
      "('raven', 'NN') det ('a', 'DT')\n",
      "('laughed', 'VBD') nsubj ('man', 'NN')\n",
      "('man', 'NN') det ('The', 'DT')\n",
      "('man', 'NN') acl:relcl ('saw', 'VBD')\n",
      "('saw', 'VBD') nsubj ('who', 'WP')\n",
      "('saw', 'VBD') dobj ('raven', 'NN')\n",
      "('raven', 'NN') det ('the', 'DT')\n",
      "('laughed', 'VBD') compound:prt ('out', 'RP')\n",
      "('laughed', 'VBD') advmod ('loud', 'JJ')\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "I shot an elephant in my pajamas.\n",
    "The elephant was seen by a giraffe.\n",
    "The bird I need is a raven.\n",
    "The man who saw the raven laughed out loud.\n",
    "\"\"\"\n",
    "\n",
    "for pred in generate_predicates_for_text(text):\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hausaufgaben\n",
    "### Aufgabe 3 &nbsp;&nbsp;&nbsp; Parent Annotation\n",
    "*Parent Annotation* kann die Performanz einer CFG wesentlich verbessern. Schreiben Sie eine Funktion, die einen gegebenen Syntaxbaum dieser Optimierung unterzieht. Auf diese Art und Weise transformierte Bäume können dann wiederum zur Grammatikinduktion verwendet werden.\n",
    "\n",
    "`parentHistory` soll dabei die Anzahl der Vorgänger sein, die zusätzlich zum direkten Elternknoten berücksichtigt werden. (Kann bei der Lösung der Aufgabe auch ignoriert werden.)\n",
    "\n",
    "`parentChar` soll ein Trennzeichen sein, das bei den neuen Knotenlabels zwischen dem ursprünglichen Knotenlabel und der Liste von Vorgängern eingefügt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parent_annotation(tree, parentHistory=0, parentChar=\"^\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tree = nltk.Tree(\n",
    "    \"S\",\n",
    "    [\n",
    "        nltk.Tree(\"NP\", [\n",
    "            nltk.Tree(\"DET\", []),\n",
    "            nltk.Tree(\"N\", [])\n",
    "        ]),\n",
    "        nltk.Tree(\"VP\", [\n",
    "            nltk.Tree(\"V\", []),\n",
    "            nltk.Tree(\"NP\", [\n",
    "                nltk.Tree(\"DET\", []),\n",
    "                nltk.Tree(\"N\", [])\n",
    "            ])\n",
    "        ])\n",
    "    ]\n",
    ")\n",
    "\n",
    "parent_annotation(\n",
    "   test_tree\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4 &nbsp;&nbsp;&nbsp; Mehr Semantik für IE\n",
    "Zusätzlich zu den in Aufgabe 2 behandelten Konstruktionen sollen jetzt auch negierte und komplexe Sätze mit Konjunktionen sinnvoll verarbeitet werden.\n",
    "\n",
    "Eingabe:\n",
    "\n",
    "    I see an elephant.\n",
    "    You didn't see the elephant.\n",
    "    Peter saw the elephant and drank wine.\n",
    "    \n",
    "Gewünschte Ausgabe:\n",
    "\n",
    "    see(I, elephant)\n",
    "    not_see(You, elephant)\n",
    "    saw(Peter, elephant)\n",
    "    drank(Peter, wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kopieren Sie am besten Ihren aktuellen Stand von oben herunter und fügen Sie Ihre Erweiterungen dann hier ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_predicates_for_sentence(sentence):\n",
    "    pass\n",
    "def generate_predicates_for_text(text):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "I see an elephant.\n",
    "You didn't see the elephant.\n",
    "Peter saw the elephant and drank wine.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
